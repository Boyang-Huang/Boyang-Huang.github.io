<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Hi, this is Nelson. Please DELETE the <script> block below (L6-L13)
          if you use this HTML, otherwise my analytics will track your page.
	    <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-51640218-1', 'auto');
            ga('send', 'pageview');
        </script>-->
        <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <title>Boyang Huang</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="http://boyang-huang.github.io" />
	    <meta property="og:title" content="Boyang Huang" />
	    <meta property="og:image" content="http://boyang-huang.github.io/img/me.jpg" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Boyang Huang">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" crossorigin="anonymous">
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col-lg-3 col-md-4">
                    <img class="img-fluid rounded" src="img/me.jpg" alt="Boyang Huang">
                    <p>
                        <i class="fa fa-envelope pt-3"></i> boyangh@ucsd.edu
                    </p>
                </div>
                <div class="col-lg-9 col-md-8">
                    <h1>Boyang Huang</h1>
                    <p>
                        Hi! I am a second-year master's student in the <a href="https://cse.ucsd.edu/" target="_blank">Computer Science & Engineering</a> department at the <a href="https://ucsd.edu/" target="_blank">University of California San Diego</a>, where I'm very fortunate to work with Professor <a href="https://cseweb.ucsd.edu/~russell/" target="_blank">Russell Impagliazzo</a> and <a href="https://barnasaha.net/" target="_blank">Barna Saha</a>. My research interest is in computational complexity theory and algorithm design.
                        I'm also broadly interested in theoretical computer science and mathematics.
                    </p>
                    <p>
                        Prior to UCSD, I received undergraduate degrees in computer science and honors mathematics from the <a
                        href="https://umich.edu/" target="_blank">University of Michigan Ann Arbor</a>.
                    </p>
                    <p>
                        I am deeply thankful to all my research advisors, mentors, and collaborators for guiding me into theory research. I am
                        also extremely grateful to all my previous professors and instructors for introducing me to the beautiful world of mathematics.
                    </p>
                    <p>
                        [<a href="files/CV.pdf" target="_blank">CV</a>] [<a href="https://scholar.google.com/citations?user=5yGINzAAAAAJ&hl=en" target="_blank">Google Scholar</a>] 
                    </p>
                </div>
            </div>
            <!--<div class="row">
                <div class="col">
                    <h2>Recent News</h2>
                    <ul>
                        <li>
                            Some news item here.
                        </li>
                        <li>
                            Some other news item here.
                        </li>
                    </ul>
                </div>
            </div>-->
            <hr>
            <div class="row" id="research">
                <div class="col">
                    <h2>Research</h2>
                    <p>All co-authors are listed in alphabetical order.</p>
                    <ul class="pl">
                        <li>
                            <b>Subquadratic Algorithms and Hardness for Attention with Any Temperature</b>
                            <br />
                            with <a href>Shreya Gupta</a>,
                            <a href="https://barnasaha.net/" target="_blank">Barna Saha</a>,
                            <a href="http://xuyinzhan.github.io/" target="_blank">Yinzhan Xu</a>,
                            and <a href="https://czye17.github.io/" target="_blank">Chris Ye</a>.
                            <br />
                            [<a href="#" onclick="$('#subquadratic-algorithms-and-hardness-for-attention-abstract').toggle();return false;">abstract</a>]
                            [<a href="https://arxiv.org/abs/2505.14840" target="_blank">arXiv</a>]
                            <div id="subquadratic-algorithms-and-hardness-for-attention-abstract" class="abstract" style="display:none;">
                                <p>
                                    Despite the popularity of the Transformer architecture, the standard algorithm for computing Attention suffers from
                                    quadratic time complexity in context length $n$. Alman and Song [NeurIPS 2023] showed that when the head dimension $d =
                                    \Theta(\log n)$, subquadratic Attention is possible if and only if the inputs have small entries bounded by $B =
                                    o(\sqrt{\log n})$ in absolute values, under the Strong Exponential Time Hypothesis ($\mathsf{SETH}$). Equivalently,
                                    subquadratic Attention is possible if and only if the softmax is applied with high temperature for $d=\Theta(\log n)$.
                                    Running times of these algorithms depend exponentially on $B$ and thus they do not lead to even a polynomial-time
                                    algorithm outside the specific range of $B$.
                                </p>
                                <p>
                                    This naturally leads to the question: when can Attention be computed efficiently without strong assumptions on
                                    temperature? Are there fast attention algorithms that scale polylogarithmically with entry size $B$? In this work, we
                                    resolve this question and characterize when fast Attention for arbitrary temperatures is possible. First, for all
                                    constant $d = O(1)$, we give the first subquadratic $\tilde{O}(n^{2 - 1/d} \cdot \mathrm{polylog}(B))$ time algorithm
                                    for Attention with large $B$. Our result holds even for matrices with large head dimension if they have low rank. In
                                    this regime, we also give a similar running time for Attention gradient computation, and therefore for the full LLM
                                    training process. Furthermore, we show that any substantial improvement on our algorithm is unlikely. In particular, we
                                    show that even when $d = 2^{\Theta(\log^* n)}$, Attention requires $n^{2 - o(1)}$ time under $\mathsf{SETH}$.
                                </p>
                                <p>
                                    Finally, in the regime where $d = \mathrm{poly}(n)$, the standard algorithm requires $O(n^{2} d)$ time while previous
                                    lower bounds only ruled out algorithms with truly subquadratic time in $n$. We close this gap and show that the standard
                                    algorithm is optimal under popular fine-grained complexity assumptions.
                                </p> 
                            </div>
                        </li>
                        <br>
                        <li>
                            <b>The Computational Complexity of Factored Graphs</b>
                            <br/>
                            with <a href>Shreya Gupta</a>,
                            <a href="https://cseweb.ucsd.edu/~russell/" target="_blank">Russell Impagliazzo</a>,
                            <a href>Stanley Woo</a>,
                            and <a href="https://czye17.github.io/" target="_blank">Chris Ye</a>.
                            <br/>
                            <a href="http://itcs-conf.org/" target="_blank">
                                <b>16th Innovations in Theoretical Computer Science (ITCS) conference</b></a>, 2025.
                            <br/>
                            [<a href="#" onclick="$('#computational-complexity-of-factored-graphs-abstract').toggle();return false;">abstract</a>]
                            [<a href="https://arxiv.org/abs/2407.19102" target="_blank">arXiv</a>]
                            [<a href="files/Factored Graphs Presentation.pdf" target="_blank">slides</a>] 
                            [<a href="https://youtu.be/F-FMxNOFOcc" target="_blank">video</a>]
                            [<a href="https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2025.58" target="_blank">ITCS</a>]
                            <div id="computational-complexity-of-factored-graphs-abstract" class="abstract" style="display:none;">
                                <p>
                                    While graphs and abstract data structures can be large and complex, practical instances are often regular or
                                    highly
                                    structured. If the instance has sufficient structure, we might hope to compress the object into a more succinct
                                    representation. An efficient algorithm (with respect to the compressed input size) could then lead to more
                                    efficient
                                    computations than algorithms taking the explicit, uncompressed object as input. This leads to a natural
                                    question: when
                                    does knowing the input instance has a more succinct representation make computation easier?
                                </p>
                                <p>
                                    We initiate the study of the computational complexity of problems on factored graphs: graphs that are given as a
                                    formula
                                    of products and unions on smaller graphs. For any graph problem, we define a parameterized version that takes
                                    factored
                                    graphs as input, parameterized by the number of (smaller) ordinary graphs used to construct the factored graph.
                                    In this setting, we characterize the parameterized complexity of several natural graph problems, exhibiting a
                                    variety of
                                    complexities.
                                    We show that a decision version of lexicographically first maximal independent set is <b>XP</b>-complete, and
                                    therefore <i>unconditionally</i> not fixed-parameter tractable (<b>FPT</b>). On the other hand, we show that
                                    clique
                                    counting is <b>FPT</b>. Finally, we show that reachability is <b>XNL</b>-complete. Moreover, <b>XNL</b> is
                                    contained in <b>FPT</b> if and only if <b>NL</b> is contained in some fixed polynomial time.
                                </p>
                            </div>
                        </li>
                        <br>
                        <li>
                            <b>The Greedy Coin Change Problem</b>
                            <br />
                            with <a href>Shreya Gupta</a> and
                            <a href="https://cseweb.ucsd.edu/~russell/" target="_blank">Russell Impagliazzo</a>.
                            <br />
                            [<a href="#"
                                onclick="$('#greedy-coin-change-abstract').toggle();return false;">abstract</a>]
                            [<a href="https://arxiv.org/abs/2411.18137" target="_blank">arXiv</a>]
                            <div id="greedy-coin-change-abstract" class="abstract" style="display:none;">
                                <p>
                                The <i>Coin Change</i> problem, also known as the Change-Making problem, is a well-studied combinatorial optimization
                                problem, which involves minimizing the number of coins needed to make a specific change amount using a given set of coin
                                denominations.
                                A natural and intuitive approach to this problem is the greedy algorithm.
                                While the greedy algorithm is not universally optimal for all sets of coin denominations, it yields optimal solutions
                                under most real-world coin systems currently in use, making it an efficient heuristic with broad practical
                                applicability.
                                Researchers have been studying ways to determine whether a given coin system guarantees optimal solutions under the
                                greedy approach, but surprisingly little attention has been given to understanding the general computational behavior of
                                the greedy algorithm applied to the coin change problem.
                                </p>
                                <p>
                                To address this gap, we introduce the <i>Greedy Coin Change</i> problem and formalize its decision version: given a
                                target amount \(W\) and a set of denominations \(C\), determine whether a specific coin is included in the greedy
                                solution.
                                We prove that this problem is <b>P</b>-complete under log-space reductions, which implies it is unlikely to be
                                efficiently parallelizable or solvable in limited space.
                                </p>   
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Teaching</h2>
                    <ul>
                    <h4>UCSD</h4>
                        <li>
                            CSE 101 - Design and Analysis of Algorithms, TA. Winter 2025, Spring 2025.
                        </li>
                        <li>
                            CSE 202 - Algorithm Design and Analysis, TA. <a href="https://sites.google.com/view/qipengliu/cse202?authuser=0">Fall 2024</a>.
                        </li>
                        <li>
                            CSE 105 - Theory of Computing, TA. Spring 2024, Summer 2024. 
                        </li>
                    </ul>
                    <ul>
                        <h4>UM</h4>
                        <li>
                            MATH 396 - Honors Multivariable Analysis II, TA. Winter 2023.
                        </li>
                        <li>
                            MATH 395 - Honors Multivariable Analysis I, TA. Fall 2022.
                        </li>
                        <li>
                            MATH 297 - Honors Introduction to Real Analysis, TA. Winter 2022.
                        </li>
                        <li>
                            MATH 412 - Introduction to Abstract Algebra, TA. Winter 2021, Fall 2021.
                        </li>
                        <li>
                            MATH 217 - Linear Algebra, Tutor. Fall 2020, Winter 2021, Fall 2021.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellany</h2>
                    <ul>
                        <li>
                            Thanks to <a href="https://cs.stanford.edu/~nfliu/" target="_blank">Nelson</a> for sharing the source code of his personal website.
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Last updated: May 30, 2025
                        </p>
                    </div>
                    <div class="col-6 col-md text-right">
                        <a href="https://umich.edu/" class="image-link">
                            <img class="mr-4" src="img/umich-logo.png" alt="Univeristy of Michigan logo." height="25">
                        </a>
                        <a href="https://ucsd.edu/" class="image-link">
                            <img src="img/ucsd-logo.png" alt="UC San Diego logo." height="25">
                        </a>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
